{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPgMfCBhaBtECes6JH4qs7B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"l0SVjeRUpN1l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -r '/content/drive/MyDrive/Colab Notebooks/requirements.txt'"],"metadata":{"id":"rHm9S4I55yd-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","import re\n","import nltk\n","nltk.download('stopwords')\n","from nltk.tokenize import TweetTokenizer\n","from nltk.corpus import stopwords\n","from nltk.stem import SnowballStemmer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from nltk.tokenize.treebank import TreebankWordDetokenizer\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, plot_confusion_matrix\n","import skfuzzy as fuzz\n","import skfuzzy.control as ctrl"],"metadata":{"id":"EwgfZYDqLb-Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/Colab\\ Notebooks/utils.py .\n","from utils import preprocess_tweet"],"metadata":{"id":"AhAJNilOfe7c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Análisis inteligente de datos guiado por ingeniería del conocimiento, un caso práctico: radicalización y odio en redes sociales."],"metadata":{"id":"5WEfIxiG1IFX"}},{"cell_type":"markdown","source":["A lo largo del taller se mostrarán ejemplos explícitos de Discurso de Odio para ilustrar el desarrollo. La finalidad del taller es formativa y en ningún momento se pretende ofender al público. Para paliar la lacra del contenido de odio en la red es necesario conocerlo.\n","\n","\n"],"metadata":{"id":"v-PSRI3I0_31"}},{"cell_type":"markdown","source":["El **Departamento de Seguridad Nacional** nos ha encargado un prototipo de un **sistema de alerta temprana** que les avise si se produce algún altercado de odio en Twitter. \n","\n","El sistema deberá **detectar el discurso de odio en español en la red social Twitter** y **avisar** al Departamente de Seguridad Nacional **únicamente en el caso de que el discurso de odio sea de tal calado que pueda estar cerca de suponer un peligro para la convivencia pacífica y el orden público**."],"metadata":{"id":"4J1VS6d_1Yia"}},{"cell_type":"markdown","source":["Recopilando, necesitamos:\n","\n","\n","\n","1.   **Un sistema que automáticamente nos diga si un mensaje es de odio o no es de odio.**\n","2.   **Un modelo de razonamiento que nos permita inferir la intensidad del discurso de odio en base a una serie de parámetros predefinidos.**\n","\n"],"metadata":{"id":"73UA_mQwB1jc"}},{"cell_type":"markdown","source":["## Clasificación automáticas de mensajes de odio."],"metadata":{"id":"KzS-KQqG1sqo"}},{"cell_type":"markdown","source":["Para resolver el problema de clasificación automática de mensajes de odio vamos a emplear el conjunto de datos **HATERNET**. Este conjunto de datos está formado por 6000 tweets etiquetados manualmente como odio y no odio.\n","\n","*Pereira-Kohatsu, J.C.; Quijano-Sánchez, L.; Liberatore, F.; Camacho-Collados, M. Detecting and Monitoring Hate Speech in Twitter. Sensors 2019, 19, 4654. https://doi.org/10.3390/s19214654*"],"metadata":{"id":"V3-Mn7u_JlxV"}},{"cell_type":"markdown","source":["### Análisis exploratorio de datos"],"metadata":{"id":"xdsS2W01KFlX"}},{"cell_type":"markdown","source":["Análisis preliminar de un conjunto de datos para resumir sus principales características, donde a menudo se emplean métodos visuales."],"metadata":{"id":"yXWu9dMALCVq"}},{"cell_type":"code","source":["# Leemos las 10 primeras líneas\n","haternet_path = \"/content/drive/MyDrive/Colab Notebooks/HATERNET.txt\"\n","with open(haternet_path) as archivo:\n","    head = [next(archivo) for x in range(10)]\n","print(\"\\n\".join(head))"],"metadata":{"id":"lvY3QLeOQixC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cargamos el dataset\n","haternet_df = pd.read_csv(haternet_path, sep=..., names=['id','tweet','clase'], engine='python')"],"metadata":{"id":"jqH4Xt5TRRfv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Obtenemos información del data frame y los tipos de variable\n","haternet_df.info()"],"metadata":{"id":"r0bOr6NKRh3Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Miramos la distribución de clases\n","print(...(haternet_df['...']))"],"metadata":{"id":"FbgQIRSJRmZL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cambiamos los tipos de datos\n","haternet_df = haternet_df.astype({\"id\": \"string\", \"tweet\": \"string\", \"clase\":\"category\"})"],"metadata":{"id":"Ngc3dX_iRpSR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vamos a ver algunas estadísticas\n","print(haternet_df.describe())"],"metadata":{"id":"MRTl2HFuR1Sq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Miramos el tweet duplicado\n","haternet_df[haternet_df['tweet'].isin(haternet_df['tweet'][haternet_df['tweet'].duplicated()])]"],"metadata":{"id":"4Nm8J7ZuR6M0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vemos la distribución de las clases\n","sns.catplot(data=haternet_df, x=\"clase\", kind=\"count\", palette=\"ch:.25\")"],"metadata":{"id":"feJmXz6vSKCZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hacemos una copia del dataframe\n","haternet_df_copia = haternet_df\n","# Creamos una nueva columna con la longitud de los mensajes\n","haternet_df_copia['longitud'] = ..."],"metadata":{"id":"WP0sX2GnSPh3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vamos a ver la distribución de longitud de los mensajes\n","sns.displot(..., x=\"...\",bins=20)"],"metadata":{"id":"JvW_JPVhSHfe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Primero aquellos tweets de más de 280 caracteres\n","pd.options.display.max_colwidth = 400\n","print(haternet_df_copia[\"tweet\"][haternet_df_copia.longitud > 280])"],"metadata":{"id":"ZOXMRaBXShTU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vamos a seleccionar uno aleatorio\n","haternet_df_copia[\"tweet\"].loc[np.random.choice(haternet_df_copia[\"tweet\"][...].index)]"],"metadata":{"id":"PPi-QHxATr8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Miramos los tweets cortos\n","print(haternet_df_copia[\"tweet\"][...])"],"metadata":{"id":"RMj4B09CUf7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Unimos los mensajes\n","texto_odio = (\" \").join(haternet_df[\"tweet\"][haternet_df.clase == 1])\n","texto_noOdio = ..."],"metadata":{"id":"tfKoKtC4Uon6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generamos una nube de términos para los tweets etiquetados como odio\n","wordcloud_odio = WordCloud().generate(texto_odio)\n","plt.imshow(wordcloud_odio,interpolation='bilinear')\n","plt.axis(\"off\")\n","plt.show()"],"metadata":{"id":"iQCZ_RrrVLZX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generamos una nube de términos para los tweets etiquetados como no odio\n","wordcloud_noOdio = WordCloud().generate(texto_noOdio)\n","plt.imshow(wordcloud_noOdio,interpolation='bilinear')\n","plt.axis(\"off\")\n","plt.show()"],"metadata":{"id":"uRAyhLQPVSt8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preprocesamiento"],"metadata":{"id":"EFZJcScEKtVI"}},{"cell_type":"markdown","source":["En esta fase se manipulan los mensajes para dejar aquel contenido útil para la posterior fase de análisis. En la fase de preprocesamiento incluye la limpieza, eliminación de ruido y, también una representación intermedia previa al proceso de transformación."],"metadata":{"id":"zS-peY0GL0_o"}},{"cell_type":"code","source":["# Eliminar el contenido duplicado\n","haternet_df = haternet_df.drop_duplicates(subset=['...'])"],"metadata":{"id":"jDVkdmc-VnY3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comprobamos que ya no hay duplicados\n","print(...)"],"metadata":{"id":"lcZ6kHU1VtPN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Balanceamos las clases\n","# Función random undersampling\n","def RUS(df):\n","    clase_positiva = df[df['clase']==1]\n","    clase_negativa = ...\n","    \n","    num_pos = len(clase_positiva)\n","    num_neg = ...\n","\n","    if (num_pos > num_neg):\n","        fraccion = num_neg / num_pos\n","        submuestreo = pd.concat([clase_positiva.sample(frac = fraccion, random_state = 78),clase_negativa],axis=0)\n","    else:\n","        fraccion = ...\n","        submuestreo = ...\n","    \n","\n","    return submuestreo.sort_index().reset_index()"],"metadata":{"id":"qG6s4y4NVyFy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Aplicamos la función\n","haternet_df_b = ..."],"metadata":{"id":"kEDOwSLlV_AJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comprobamos que los tweets están balanceados\n","sns.catplot(data=..., x=\"...\", kind=\"...\", palette=\"ch:.25\")"],"metadata":{"id":"DnPGhrIqWHUD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La **tokenización** es la división del texto en unidades individuales denominadas tokens que posteriormente actuarán de características para nuestro modelo."],"metadata":{"id":"qubOVnTYn0CN"}},{"cell_type":"code","source":["# Cargamos el tokenizador\n","tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)"],"metadata":{"id":"TVBocTQ_Wkfx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenizamos\n","haternet_df_b['tokens'] = [tokenizer.tokenize(tweet) for tweet in haternet_df_b['tweet']]"],"metadata":{"id":"HP2f5OzEWrf1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mostramos el dataframe para ver la tokenización\n","haternet_df_b"],"metadata":{"id":"-pMh_W3Y9hub"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Empezamos el proceso de limpieza de los mensajes"],"metadata":{"id":"n0WpZxN_9X8U"}},{"cell_type":"code","source":["# Eliminamos los emojis\n","def eliminarEmojis(texto):\n","    regrex_pattern = re.compile(pattern = \"[\"\n","        u\"\\U0001F600-\\U0001F64F\"  # emoticonos\n","        u\"\\U0001F300-\\U0001F5FF\"  # símbolos\n","        u\"\\U0001F680-\\U0001F6FF\"  # transporte y mapas\n","        u\"\\U0001F1E0-\\U0001F1FF\"  # banderas\n","                           \"]+\", flags = re.UNICODE)\n","    return regrex_pattern.sub(r'',texto)\n","\n","haternet_df_b['tokens'] = haternet_df_b['tokens'].apply(lambda tokens: [eliminarEmojis(palabra) for palabra in tokens])"],"metadata":{"id":"xm3C_YQyW2s4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comprobamos que se han elimiado los emojis\n","haternet_df_b['tokens']"],"metadata":{"id":"2eCoYN6z9y5o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Eliminamos las urls\n","# http o https o www seguido de cualquier caracter\n","url_rx = re.compile(r'(http(s)?).+|www\\..+')\n","haternet_df_b['tokens'] = haternet_df_b['tokens'].apply(lambda tokens: [palabra for palabra in tokens if not url_rx.match(palabra)])"],"metadata":{"id":"Wdp8U7E_XAu2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comprobamos si las URLs se han eliminado\n","haternet_df_b"],"metadata":{"id":"tD03qewM98fj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Eliminamos los números\n","numeros_rx = re.compile(r'^[0-9]+$')\n","haternet_df_b['tokens'] = ..."],"metadata":{"id":"eoD-6Lm7XIln"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comprobamos que se han eliminado los números\n","haternet_df_b"],"metadata":{"id":"-R1aMjF0-Iiq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Eliminamos los signos de puntuación\n","haternet_df_b['tokens'] = haternet_df_b['tokens'].apply(lambda tokens: [re.sub(r'^([^\\w]|_)+$', '', palabra) for palabra in tokens])"],"metadata":{"id":"VverMwjdXLqp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comprobamos que se han eliminado los signos de puntuación\n","..."],"metadata":{"id":"luBRQdgx-Xzg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Eliminamos las palabras vacías\n","# Observamos la lista de palabras vacías que nos proporciona la librería nltk\n","print(stopwords.words('spanish'))\n","# Vemos que las palabras está acentuadas y como bien sabemos Twitter no se define precisamente por sus buenos escritores"],"metadata":{"id":"aVvAkZzLXTq0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Replicamos la lista de palabras vacías con los acentos eliminados.\n","def eliminar_acentos(texto):\n","    texto = re.sub(r\"[àáâãäå]\", 'a', texto)\n","    texto = re.sub(r\"[èéêë]\", 'e', texto)\n","    texto = re.sub(r\"[ìíîï]\", 'i', texto)\n","    texto = re.sub(r\"[òóôõö]\", 'o', texto)\n","    texto = re.sub(r\"[ùúûü]\", 'u', texto)\n","    return texto\n","\n","stop_words_sin_acentuar = ...\n"],"metadata":{"id":"BYXqL1sI_Dmt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Miramos la lista de las palabras vacías sin acentuar\n","print(...)"],"metadata":{"id":"IKVOtirnAKs6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Eliminamos las palabras vacías\n","haternet_df_b['tokens'] = haternet_df_b['tokens'].apply(lambda tokens: [palabra for palabra in tokens if palabra not in stopwords.words('spanish') and ...])"],"metadata":{"id":"TL8Wt2xJ-mFT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comprobamos que se han eliminado las palabras vacías\n","..."],"metadata":{"id":"HCyf4fHMLq6F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Definimos algunos términos de propios de la jerga de twitter y los eliminamos\n","# Por ejemplo el jajaja y el xd\n","jerga_rx = re.compile(r'^(j(j)?(a)?)[aj]*|(xd)[d]*$')\n","# Eliminamos esos tokens\n","haternet_df_b['tokens'] = ..."],"metadata":{"id":"PnnPjypaJoLf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vamos a eliminar los huecos vacíos que han quedado después de limpiar los mensajes\n","# Eliminamos los tokens vacíos\n","haternet_df_b['tokens'] = haternet_df_b['tokens'].apply(lambda tokens: [palabra for palabra in tokens if ...])"],"metadata":{"id":"JVLZp2kdB9CX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Segmentación (Stemming) y lematización** son métodos empleados para **reducir el tamaño del vocabulario** buscando su forma morfológica, raíz o lemas.\n","\n"],"metadata":{"id":"PlB0enJKn_0M"}},{"cell_type":"code","source":["# Stemming de los mensajes\n","stemmer_esp = SnowballStemmer('spanish')\n","\n","haternet_df_b['tokens'] = haternet_df_b['tokens'].apply(...)"],"metadata":{"id":"mcZxpBmt7lKu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Volvemos a visualizar la nube de términos\n","# Unimos los tokens en un solo string\n","texto = (\" \").join(token for tweet  in haternet_df_b[\"tokens\"] for token in tweet)\n","# Visualizamos la frecuencia de las palabras\n","wordcloud_haternet = WordCloud().generate_from_text(texto)\n","plt.imshow(wordcloud_haternet,interpolation='bilinear')\n","plt.axis(\"off\")\n","plt.show()"],"metadata":{"id":"qLOT5QdQ7tuN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Transformación"],"metadata":{"id":"BhMhqXmmK1Mu"}},{"cell_type":"markdown","source":["Fase en la que **transformamos nuestros mensajes para que puedan servir como entrada a un algoritmo de aprendizaje**. Esta transformación puede llevarse a cabo mediante la aplicación de diversos métodos como la **vectorización con bolsas de palabras** o los **word embedings**."],"metadata":{"id":"fW0LU451rW9h"}},{"cell_type":"code","source":["# Vectorización \n","# Definimos la función TF-IDF\n","vectorizer = TfidfVectorizer(lowercase=False, min_df = 15)"],"metadata":{"id":"TLLI_ogM8IC3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creamos un corpus con todos los mensajes del dataset eliminando la tokenización\n","corpus = [TreebankWordDetokenizer().detokenize(tweet) for tweet in haternet_df_b['tokens']]"],"metadata":{"id":"8ZwUgEVYEqcm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vectorizamos la entrada\n","X = vectorizer.fit_transform(corpus)\n","# Asiganmos las etiquetas a una nueva variable\n","y = haternet_df_b['clase']"],"metadata":{"id":"WfLS8N_IEyNF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mostramos el número de documentos y el de características\n","print(X.shape)"],"metadata":{"id":"R-_hpp_eGogN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observamos algunos de nuestros términos que actúan como características\n","print(vectorizer.get_feature_names_out())"],"metadata":{"id":"4UF5zdbaI26H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vemos la estructura de nuestros parámetros de entrada\n","print(X.toarray()[0])"],"metadata":{"id":"056mN6ZvHF4O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Clasificación"],"metadata":{"id":"eOzcSLeuK41-"}},{"cell_type":"markdown","source":["Para la clasificicación de mensajes de odio vamos a emplear el algoritmo llamado **Máquinas de Soporte Vectorial (SVM)**. El motivo es porque en la literatura es el más empleado para esta tarea."],"metadata":{"id":"gmUX0h9n2NsV"}},{"cell_type":"code","source":["# Dividimos el conjunto de datos en entrenamiento y test\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"],"metadata":{"id":"aMOG6a6mDfz-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cargamos el algoritmo\n","svc = svm.SVC()"],"metadata":{"id":"VfXuVPHQEO8Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Definimos la búsqueda en grid asignándole varios valores a cada uno de los hiperparámetros\n","param_grid = {'C': [0.1, 1, 10, 50, 100, 1000],  \n","              'gamma': [0.01, 0.001, 0.0001, 0.00001],\n","              'kernel': ['rbf']}"],"metadata":{"id":"m_yS_U_K8kqL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# El verbose es para que nos muestre información\n","# Definimos el modelo\n","model = GridSearchCV(estimator = ..., param_grid = ..., cv = 5, verbose = 3)"],"metadata":{"id":"R3BOFsSFEa0C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Entrenamos\n","model.fit(X = ..., y = ...)"],"metadata":{"id":"aZFm6GDu8qko"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluación"],"metadata":{"id":"TGKlkBA2K8Ka"}},{"cell_type":"markdown","source":["Para la evaluación del modelo vamos a emplear una serie de métricas que nos van a dar una visión sobre cómo ha funcionado nuestro modelo frente a ejemplos no vistos en el proceso de entrenamiento.\n","\n","\n","\n"],"metadata":{"id":"1sgv1Jme7xtc"}},{"cell_type":"code","source":["# Seleccionamos el mejor modelo\n","mejor_modelo = model.best_estimator_"],"metadata":{"id":"8GdwnfN-9JWc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lo probamos con nuestro test\n","y_pred = ..."],"metadata":{"id":"WcYPkm0nNKos"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observamos la matriz de confusión\n","plot_confusion_matrix(mejor_modelo, X_test, y_test)  \n","plt.show()"],"metadata":{"id":"wtNXisrLNOqM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mostramos las métricas \n","print(classification_report(..., ...))"],"metadata":{"id":"Ni6Dyhe59LhN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Motor de inferencia para evaluar la intensidad del discurso de odio."],"metadata":{"id":"JBq90tmCCUBo"}},{"cell_type":"markdown","source":["Para medir la intensidad del discurso de odio vamos a emplear un mecanismo de inferencia **basado en palabras** en lugar de en números. Esto se conoce como **computación con palabras** o *computing with words* en inglés. El término lo acuñó el profesor Lotfi Zadeh, creador de la lógica borrosa."],"metadata":{"id":"HYCepYy88oPN"}},{"cell_type":"markdown","source":["Para construir el motor de razonamiento necesitamos una base de conocimiento.\n","\n"],"metadata":{"id":"JWC-h54huz8f"}},{"cell_type":"markdown","source":["Una base de conocimiento está formada por:\n","\n","*   Base de datos que contiene los conjuntos de términos lingüísticos empleados para describir cada una de las clases de la taxonomía y funciones de pertenencia asociadas a estos términos lingüísticos que definen la semántica dentro de un dominio predefinido. Esas funciones de pertenencia pueden ser triangulares o trapezoidales entre otras.\n","*   Base de reglas que está formada por una colección de reglas lingüísticas con la siguiente estructura: \n","$$\\text{Si  } X_1 \\text{ es } A_1 \\text{ y } \\text{ ... } \\text{ y } X_n \\text{ es } A_n \\text{ entonces } Y \\text{ es } B$$\n","\n"],"metadata":{"id":"bzIdhe-HvgBJ"}},{"cell_type":"markdown","source":["**Definición del universo de discurso del primer nivel de la taxonomía**\n"],"metadata":{"id":"26JNfXLRwvSZ"}},{"cell_type":"code","source":["# Variables borrosas\n","seguidores = ctrl.Antecedent(np.arange(0,90001,1), 'seguidores')\n","# Universo de discurso entre 0 y 1 con una granularidad de 0.01\n","tipo_emisor = ...\n","\n","influencia_emisor_cons = ctrl.Consequent(np.arange(0, 1.01, 0.01), 'influencia_emisor')\n","\n","# Universo de discurso entre 0 y 20000 con una granularidad de 1\n","likes = ...\n","retweets = ctrl.Antecedent(np.arange(0,10001,1), 'retweets')\n","\n","# Universo de discurso entre 0 y 1 con una granularidad de 0.01\n","impacto_mensaje_cons = ctrl.Consequent(np.arange(0, 1.01, 0.01), 'impacto_mensaje')\n"],"metadata":{"id":"Yxqr1-AaeTef"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Definición de las funciones de pertenencia del primer nivel de la taxonomía**"],"metadata":{"id":"2G4MacK_owf9"}},{"cell_type":"code","source":["# Número de seguidores\n","seguidores['Pocos'] = fuzz.trimf(seguidores.universe, [0, 0, 5000])\n","seguidores['Algunos'] = fuzz.trapmf(seguidores.universe, [0, 5000, 10000,20000])\n","seguidores['Bastantes'] = fuzz.trapmf(seguidores.universe, [10000, 20000, 40000, 60000])\n","seguidores['Muchos'] = fuzz.trimf(seguidores.universe, [40000, 90000, 90000])"],"metadata":{"id":"7Zyo0mjf9Zan"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vamos a ver algunas de las funciones de pertenencia definidas en base a un conocimiento experto\n","seguidores.view()"],"metadata":{"id":"c9LhMgea9e3C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tipo de emisor\n","etiquetas_tip_emi = ['No_verificada','Verificada']\n","tipo_emisor['No_verificada'] = fuzz.trimf(tipo_emisor.universe, [0, 0, 1])\n","tipo_emisor['Verificada'] = fuzz.trimf(tipo_emisor.universe, [0, 1, 1])\n","\n","# Influencia del emisor\n","etiquetas_inf_em = ['Muy_baja','Baja','Media','Alta','Muy_alta']\n","influencia_emisor_cons.automf(names = etiquetas_inf_em)\n","# Likes\n","# Etiquetas lingüísticas Pocos, Bastantes y Muchos con funciones de pertenencia triangular, trapezoidal y triangular respectivamente\n","# La primera función de pertenencia triangular va de 0 a 1.000 con el mayor grado de pertenencia en el 0\n","likes...\n","# La segunda función de pertenencia trapezoidal va del 0 a 10.000 con el máximo grado de pertenencia entre el 1.000 y el 2.000\n","likes...\n","# La tercera función de pertenencia triangular va del 2.000 al 20.000 con el mayor grado de pertenencia en el 20.000\n","likes...\n","\n","# Retweets\n","retweets['Pocos'] = fuzz.trimf(retweets.universe, [0, 0, 500])\n","retweets['Bastantes'] = fuzz.trapmf(retweets.universe, [0, 800, 1500, 5000])\n","retweets['Muchos'] = fuzz.trimf(retweets.universe, [1500, 10000, 10000])\n","\n","# Impacto del mensaje en la sociedad\n","# Todas las funciones de pertenencia son iguales y las etiquetas son: Bajo, Medio, Alto\n","etiquetas_imp_men = ...\n","impacto_mensaje_cons ..."],"metadata":{"id":"-PvBTgIOo3vX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observamos la función de pertenencia del tipo de emisor\n","..."],"metadata":{"id":"-NuHG0tu9hJa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observamos la función de pertenencia de la influencia del emisor\n","..."],"metadata":{"id":"MH1bWgyY9ixz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observamos la función de pertenencia de los likes\n","likes.view()"],"metadata":{"id":"vt3mVt-29kcJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observamos la función de pertenencia de los retweets\n","retweets.view()"],"metadata":{"id":"dmoT671s9mAl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observamos la función de pertenencia del impacto del mensaje\n","impacto_mensaje_cons.view()"],"metadata":{"id":"ZjY81NDi9oDA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Definición del universo de discurso del segundo nivel de la taxonomía**"],"metadata":{"id":"ARvvvnNFz2_5"}},{"cell_type":"code","source":["# En todas el universo de discurso es entre 0 y 1\n","# Influencia del emisor\n","influencia_emisor_ant = ctrl.Antecedent(np.arange(0, 1.01, 0.01), 'influencia_emisor')\n","# Impacto del mensaje\n","impacto_mensaje_ant = ...\n","# Intensidad del discurso de odio\n","intensidad_odio = ctrl.Consequent(np.arange(0, 1.01, 0.01), 'intensidad_odio')"],"metadata":{"id":"UBxsAXwB9rum"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Definición de las funciones de pertenencia del segundo nivel de la taxonomía**"],"metadata":{"id":"slJy78Sh0Ucy"}},{"cell_type":"code","source":["# Todas las funciones de pertenencia son iguales\n","# Influencia del emisor\n","influencia_emisor_ant ...\n","# Impacto del mensaje en la sociedad\n","impacto_mensaje_ant ...\n","# Intensidad del discurso de odio\n","etiquetas_int_odio = ['Muy_leve','Leve','Medio','Grave','Muy_grave']\n","intensidad_odio ..."],"metadata":{"id":"BhqbNyfdeu-N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizamos la función de pertenencia de la intensidad del discurso de odio\n","intensidad_odio.view()"],"metadata":{"id":"7PhGKHR29t-5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Definición de la base de reglas que relaciona las clases de la taxonomía**"],"metadata":{"id":"9Zdw3ktC1Fv0"}},{"cell_type":"code","source":["# Definición de las reglas para obtener la influencia del emisor\n","regla_ie_1 = ctrl.Rule(antecedent=(seguidores['Pocos'] & tipo_emisor['No_verificada']), consequent = (influencia_emisor_cons['Muy_baja'])\n","# Si el número de seguidores es Algunos y el tipo de emisor es de una cuenta Verificada entonces la ingluencia del emisor es Alta\n","regla_ie_2 = ...\n","regla_ie_3 = ctrl.Rule(antecedent=(seguidores['Bastantes'] & tipo_emisor['No_verificada']), consequent = (influencia_emisor_cons['Baja']))\n","regla_ie_4 = ctrl.Rule(antecedent=(seguidores['Muchos'] & tipo_emisor['No_verificada']), consequent = (influencia_emisor_cons['Media']))\n","regla_ie_5 = ctrl.Rule(antecedent=(seguidores['Bastantes'] & tipo_emisor['Verificada']), consequent = (influencia_emisor_cons['Muy_alta']))"],"metadata":{"id":"WLWDh0ty9xe_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Definición de las reglas para obtener el impacto del mensaje\n","regla_im_1 = ctrl.Rule(antecedent=(likes['Pocos'] & retweets['Pocos']), consequent=(impacto_mensaje_cons['Bajo']))\n","regla_im_2 = ctrl.Rule(antecedent=(likes['Bastantes'] & retweets['Pocos']), consequent=(impacto_mensaje_cons['Bajo']))\n","# Si los likes son Pocos y los retweets Bastantes entonces el impacto del mensaje es Medio\n","regla_im_3 = ...\n","regla_im_4 = ctrl.Rule(antecedent=(likes['Bastantes'] & retweets['Bastantes']), consequent=(impacto_mensaje_cons['Alto']))\n","regla_im_5 = ctrl.Rule(antecedent=(likes['Muchos'] & retweets['Muchos']), consequent=(impacto_mensaje_cons['Alto']))"],"metadata":{"id":"Qfw9q6HRe7uU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Definición de las reglas para obtener la intensidad del discurso de odio\n","regla_io_1 = ctrl.Rule(antecedent=(influencia_emisor_ant['Muy_baja'] & impacto_mensaje_ant['Bajo']), consequent=(intensidad_odio['Muy_leve']))\n","regla_io_2 = ctrl.Rule(antecedent=(influencia_emisor_ant['Baja'] & impacto_mensaje_ant['Bajo']), consequent=(intensidad_odio['Leve']))\n","regla_io_3 = ctrl.Rule(antecedent=(influencia_emisor_ant['Media'] & impacto_mensaje_ant['Medio']), consequent=(intensidad_odio['Medio']))\n","# Si la influencia del emisor es Alta y el impacto del mensaje es Medio entonces la intensidad del discurso de odio es Grave\n","regla_io_4 = ...\n","regla_io_5 = ctrl.Rule(antecedent=(influencia_emisor_ant['Muy_alta'] & impacto_mensaje_ant['Alto']), consequent=(intensidad_odio['Muy_grave']))"],"metadata":{"id":"iJpRwmW091ei"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Un motor de inferencia se describe como el proces de razonamiento que combina hechos y conocimiento para emitir una conclusión.\n","\n","\n"],"metadata":{"id":"e7okEofSwtqo"}},{"cell_type":"code","source":["# Motor de inferencia influencia del emisor\n","ctrl_ie = ctrl.ControlSystem(rules =[regla_ie_1, regla_ie_2,regla_ie_3,regla_ie_4,regla_ie_5])\n","motor_ie = ctrl.ControlSystemSimulation(ctrl_ie)"],"metadata":{"id":"UPiBX4RW9507"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Motor de inferencia impacto del mensaje\n","ctrl_im = ctrl.ControlSystem(rules =[regla_im_1, regla_im_2,regla_im_3,regla_im_4,regla_im_5])\n","motor_im = ctrl.ControlSystemSimulation(ctrl_im)"],"metadata":{"id":"BFYY90S5fNkw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Motor de inferencia intensidad del odio\n","ctrl_io = ...\n","motor_io = ..."],"metadata":{"id":"6FJcwiK-985w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ejemplo de ejecución del sistema completo"],"metadata":{"id":"y9UZSx6Dho6T"}},{"cell_type":"code","source":["# Vamos a plantear un ejemplo\n","df_example = pd.DataFrame(columns=[\"tweet\", \"seguidores\", \"tipo_emisor\",\"likes\",\"retweets\",\"clase\"], \n","    data=[[\"putos moros de mierda que nos roban el trabajo\",235,0,30,10,np.NaN],\n","        [\"Si no hay trabajo para los españoles, menos para los inmigrantes. Fuera moros de nuestras fronteras\", 15300, 1, 3500, 1200,np.NaN]])"],"metadata":{"id":"lfz5l3gA9-W8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocesamos los mensajes\n","# Seleccionamos los tweets\n","X_prueba = ...\n","# Preprocesamos los tweets empleando la función preprocess_tweet\n","X_prueba = ..."],"metadata":{"id":"oE1yEtyTADz8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ayuda para conocer los parámetros de a funcion preprocess_tweet\n","help(preprocess_tweet)"],"metadata":{"id":"bB8iyj_X3odq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Detokenizamos y añadimos esos nuevos mensajes a nuestro corpus\n","n_corpus = [TreebankWordDetokenizer().detokenize(tweet) for tweet in X_prueba]\n","corpus_actualizado = corpus + n_corpus"],"metadata":{"id":"jsEJ73LkAJSz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Volvemos a vectorizar\n","X_actualizada = ..."],"metadata":{"id":"3yjfGTkBAMPE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Seleccionamos únicamente los dos últimos mensajes\n","mensajes_vectorizados = X_actualizada.toarray()\n","prueba = mensajes_vectorizados[-2:]"],"metadata":{"id":"OqUgqEV9APt2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Nueva prediccion\n","y_pred_nueva = ..."],"metadata":{"id":"pQJV_mbcASIq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vemos las etiquetas\n","y_pred_nueva"],"metadata":{"id":"s5Xt_QK2ATXi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Las añadimos a nuestro ejemplo\n","df_example['clase'] = y_pred_nueva"],"metadata":{"id":"N0wDhGRCAVZp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vamos a proporcinarle la entrada del primer mensaje a nuestro primer motor de inferencia para medir la influencia del emisor\n","motor_ie.input['seguidores'] = df_example.loc[0]['seguidores']\n","motor_ie.input['tipo_emisor'] = df_example.loc[0]['tipo_emisor']"],"metadata":{"id":"3dk4J6HNAYqL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Computamos\n","motor_ie.compute()"],"metadata":{"id":"gDG96k8qi3HQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observamos el resultado\n","print(motor_ie.output['influencia_emisor'])\n","influencia_emisor_cons.view(sim=motor_ie)"],"metadata":{"id":"McozBwSIjpY7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Función para observar qué reglas se han disparado\n","def rules_matching(ctrl_sys_sim):\n","  #Crear una lista para almacenar los resultados de las reglas\n","  rules_details = []\n","  #Recibe un simulador de sistema de control\n","  rules_count = 0\n","  #Lee las reglas asociadas\n","  for rule in ctrl_sys_sim.ctrl.rules.all_rules:\n","    rules_count+=1\n","    #Por cada regla, pasar el simulador de sistema de control\n","    rule_membership = rule.aggregate_firing[ctrl_sys_sim]\n","    if(rule_membership != 0):\n","      rules_details.append({'Regla':'Regla '+str(rules_count),\n","                            'Antecedentes':rule.antecedent,\n","                            'Consecuente':rule.consequent,\n","                            'Pertenencia':round(rule_membership,2)})\n","  return rules_details\n","\n","# Observamos qué relgas se han disparado\n","rules_matching(motor_ie)"],"metadata":{"id":"Q3L7G5iRk91B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Proporcionamos la entrada del primer mensaje a nuestro segundo motor de inferencia para medir la influencia del emisor\n","motor_im.input['likes'] = ...\n","motor_im.input['retweets'] = ...\n","# Computamos\n","motor_im.compute()\n","# Observamos los resultados\n","print(motor_im.output['impacto_mensaje'])\n","impacto_mensaje_cons.view(sim=motor_im)"],"metadata":{"id":"xsgzboM1AeBD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observamos qué relgas se han disparado\n","rules_matching(motor_im)"],"metadata":{"id":"iHb29MQhlfTy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Empleamos la salida de los dos motores de inferencia anteriores como entrada para medir la intensidad del discurso de odio\n","motor_io.input['influencia_emisor'] = motor_ie.output['influencia_emisor']\n","motor_io.input['impacto_mensaje'] = motor_im.output['impacto_mensaje']\n","# Computamos\n","motor_io.compute()\n","# Observamos los resultados\n","print(motor_io.output['intensidad_odio'])\n","intensidad_odio.view(sim=motor_io)"],"metadata":{"id":"1ydvH2hLAe0z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observamos qué relgas se han disparado\n","..."],"metadata":{"id":"rGD3csTdl0WF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vamos con la segunda configuración del modelo, medimos la influencia del emisor\n","motor_ie.input['seguidores'] = ...\n","motor_ie.input['tipo_emisor'] = ...\n","# Computamos\n","...\n","# Observamos los resultados\n","print(motor_ie.output['influencia_emisor'])\n","influencia_emisor_cons.view(sim=motor_ie)"],"metadata":{"id":"1RxCVzgaAoOQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observamos qué relgas se han disparado\n","rules_matching(motor_ie)"],"metadata":{"id":"-gCZciTWmQr7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Medimos el impacto del mensaje\n","motor_im.input['likes'] = df_example.loc[1]['likes']\n","motor_im.input['retweets'] = df_example.loc[1]['retweets']\n","# Computamos\n","motor_im.compute()\n","# Observamos los resultados\n","print(motor_im.output['impacto_mensaje'])\n","impacto_mensaje_cons.view(sim=motor_im)"],"metadata":{"id":"8ZXDkzqvAte2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observamos qué relgas se han disparado\n","rules_matching(motor_im)"],"metadata":{"id":"kqxEa1LZnDqk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Medimos la intensidad del discurso del odio\n","motor_io.input['influencia_emisor'] = motor_ie.output['influencia_emisor']\n","motor_io.input['impacto_mensaje'] = motor_im.output['impacto_mensaje']\n","# Computamos\n","motor_io.compute()\n","# Observamos los resultados\n","print(motor_io.output['intensidad_odio'])\n","intensidad_odio.view(sim=motor_io)"],"metadata":{"id":"_US2WsILAw0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observamos qué relgas se han disparado\n","rules_matching(motor_io)"],"metadata":{"id":"t1hfjbO6nPF6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Gracias por vuestra atención\n","\n","Profesor.AMontoro@uclm.es"],"metadata":{"id":"pEAl5p-O0hov"}}]}